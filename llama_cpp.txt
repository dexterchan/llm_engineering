
```
llama-server -m Llama-4-Scout-17B-16E-Instruct-Q3_K_L-00001-of-00002.gguf --port 9080 --chat-template chatml --jinja
```
curl http://localhost:9080/v1/models